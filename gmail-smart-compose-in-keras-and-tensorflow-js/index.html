<html lang="en">
  <head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="google-site-verification" content="6DIBzCM2sFIHFrOECCKoODFkMjWkvkmxMqJD0EFb7xU">
<style>
  html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;-webkit-text-decoration-skip:objects}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}.border-box,a,article,body,div,h1,header,html,p,section{-webkit-box-sizing:border-box;box-sizing:border-box}.cover{background-size:cover!important}.db{display:block}.dib{display:inline-block}.dt{display:table}.dtc{display:table-cell}@media screen and (min-width:60em){.dt-l{display:table}.dtc-l{display:table-cell}}.serif{font-family:Merriweather,georgia,times,serif}.i{font-style:italic}.fs-normal{font-style:normal}.vh-75{height:75vh}.tracked{letter-spacing:.1em}.lh-title{line-height:1.25}.lh-copy{line-height:1.5}.link{color:#f63545;text-decoration:none}.mw7{max-width:768px;max-width:48rem}.w-100{width:100%}.relative{position:relative}.dark-gray{color:#333}.mid-gray{color:#555}.pa3{padding:16px;padding:1rem}.ph0{padding-left:0;padding-right:0}.ph2{padding-left:8px;padding-left:.5rem;padding-right:8px;padding-right:.5rem}.ph3{padding-left:16px;padding-left:1rem;padding-right:16px;padding-right:1rem}.mr3{margin-right:16px;margin-right:1rem}.mb2{margin-bottom:8px;margin-bottom:.5rem}.mh0{margin-left:0;margin-right:0}@media screen and (min-width:60em){.mr4-l{margin-right:2rem}.mb0-l{margin-bottom:0}}.tr{text-align:right}.tc{text-align:center}@media screen and (min-width:60em){.tl-l{text-align:left}.tr-l{text-align:right}}.ttu{text-transform:uppercase}.f1{font-size:48px;font-size:3rem}.f3{font-size:24px;font-size:1.5rem}.f4{font-size:20px;font-size:1.25rem}.f5{font-size:16px;font-size:1rem}.f6{font-size:14px;font-size:.875rem}@media screen and (min-width:60em){.f-headline-l{font-size:4rem}.f5-l{font-size:1rem}}.measure{max-width:30em}.center{margin-right:auto;margin-left:auto}.nowrap{white-space:nowrap}.v-mid{vertical-align:middle}h1{font-weight:400}.dark-gold{color:#5a440d}.m0-auto{margin:0 auto}.measure-66ch{max-width:66ch}
</style>
<link rel="preload" href="/css/main.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="/css/main.css"></noscript>
<link rel="preload" href="/css/prism.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="/css/prism.css"></noscript>
<link rel="preload" href="/css/latex.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="/css/latex.css"></noscript>
<link href="https://fonts.googleapis.com/css?family=Merriweather:400,400i,700" rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link href="https://fonts.googleapis.com/css?family=Merriweather:400,400i,700" rel="stylesheet"></noscript>
<script>!function(n){"use strict";n.loadCSS||(n.loadCSS=function(){});var t,o=loadCSS.relpreload={};o.support=function(){var e;try{e=n.document.createElement("link").relList.supports("preload")}catch(t){e=!1}return function(){return e}}(),o.bindMediaToggle=function(t){var e=t.media||"all";function a(){t.addEventListener?t.removeEventListener("load",a):t.attachEvent&&t.detachEvent("onload",a),t.setAttribute("onload",null),t.media=e}t.addEventListener?t.addEventListener("load",a):t.attachEvent&&t.attachEvent("onload",a),setTimeout(function(){t.rel="stylesheet",t.media="only x"}),setTimeout(a,3e3)},o.poly=function(){if(!o.support())for(var t=n.document.getElementsByTagName("link"),e=0;e<t.length;e++){var a=t[e];"preload"!==a.rel||"style"!==a.getAttribute("as")||a.getAttribute("data-loadcss")||(a.setAttribute("data-loadcss",!0),o.bindMediaToggle(a))}},o.support()||(o.poly(),t=n.setInterval(o.poly,500),n.addEventListener?n.addEventListener("load",function(){o.poly(),n.clearInterval(t)}):n.attachEvent&&n.attachEvent("onload",function(){o.poly(),n.clearInterval(t)})),"undefined"!=typeof exports?exports.loadCSS=loadCSS:n.loadCSS=loadCSS}("undefined"!=typeof global?global:this);</script>

<!-- Favicons -->
<link rel="apple-touch-icon" sizes="180x180" href="/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/icons/favicon-16x16.png">
<link rel="mask-icon" href="/images/icons/safari-pinned-tab.svg" color="#5bbad5">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta name="apple-mobile-web-app-title" content="Jiayi's Chronicles">

<meta name="msapplication-TileColor" content="#ffffff">
<meta name="theme-color" content="#ffffff">

<link rel="manifest" href="/manifest.json">

    <title>Gmail Smart Compose in Keras and Tensorflow.js | Jiayi's Chronicles</title>
    <!-- Search Engine -->
<meta name="description" content="A Proof-of-Concept implementation using a sequence-to-sequence model in Keras and Tensorflow.js">
<!-- Schema.org for Google -->
<meta itemprop="name" content="Gmail Smart Compose in Keras and Tensorflow.js">
<meta itemprop="description" content="A Proof-of-Concept implementation using a sequence-to-sequence model in Keras and Tensorflow.js">
<!-- Twitter -->
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Gmail Smart Compose in Keras and Tensorflow.js">
<meta name="twitter:description" content="A Proof-of-Concept implementation using a sequence-to-sequence model in Keras and Tensorflow.js">
<meta name="twitter:site" content="@jiayi_ghu">
<meta name="twitter:image:src" content="http://blog.jiayihu.net/images/gmail-smart-compose-keras/cover.png">
<!-- Open Graph general (Facebook, Pinterest & Google+) -->
<meta name="og:title" content="Gmail Smart Compose in Keras and Tensorflow.js">
<meta name="og:description" content="A Proof-of-Concept implementation using a sequence-to-sequence model in Keras and Tensorflow.js">
<meta name="og:image" content="http://blog.jiayihu.net/images/gmail-smart-compose-keras/cover.png">
<meta name="og:url" content="http://blog.jiayihu.net/gmail-smart-compose-in-keras-and-tensorflow-js">
<meta name="og:site_name" content="Jiayi's Chronicles">
<meta name="og:type" content="website">

    <meta name="Description" content="A Proof-of-Concept implementation using a sequence-to-sequence model in Keras and Tensorflow.js">
  </head>

  <body class="page--article dark-grey lh-copy">
    <nav class="db dt-l w-100 border-box pa3 mw7 m0-auto">
  <a class="db dtc-l v-mid mid-gray link serif underline-hover w-100 tc tl-l mb2 mb0-l f3 nowrap" href="/" title="Home">
    Jiayi's Chronicles
  </a>
  <div class="db dtc-l nowrap v-mid w-100 tc tr-l">
    <a class="link underline-hover dark-gray f6 f5-l dib mr3 mr4-l" href="/" title="Home">Home</a>
    <a class="link underline-hover dark-gray f6 f5-l dib mr3 mr4-l" href="/about" title="About me">About me</a>
  </div>
</nav>


    <article>
      <header class="vh-75 dt w-100 tc cover">
        <div class="article__header dark-gold dtc v-mid">
          <h1 class="article__title f1 f-headline-l i lh-title ph3">
            Gmail Smart Compose in Keras and Tensorflow.js
          </h1>
          <div class="ph0 mh0 measure f4 lh-copy center">
            <p class="article__subtitle abstract">
              A Proof-of-Concept implementation using a sequence-to-sequence model in Keras and Tensorflow.js
            </p>
            <p class="article-meta author f6 ttu tracked fs-normal">
              Jiayi Hu - Jun 2nd 2020
            </p>
          </div>
        </div>
      </header>
      <section class="article-main f5 lh-copy ph2 relative">
        <div class="center measure-66ch m0-auto">
          <div class="tr">
            <a href="https://github.com/jiayihu/blog/tree/master/src/articles/gmail-smart-compose-keras.md" class="color-inherit f6 no-underline underline-hover glow" target="_blank" rel="noopener noreferrer">
              <span class="dib w1">
                <svg
                  viewBox="0 0 256 250"
                  version="1.1"
                  xmlns="http://www.w3.org/2000/svg"
                  xmlns:xlink="http://www.w3.org/1999/xlink"
                  preserveAspectRatio="xMidYMid"
                >
                  <g>
                    <path
                      d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z"
                      fill="#161614"
                    ></path>
                  </g>
                </svg>
              </span>
              Edit on GitHub
            </a>
          </div>
          <div class="article-content"><p><a class="dim" href="https://www.blog.google/products/gmail/subject-write-emails-faster-smart-compose-gmail/">Gmail Smart Compose</a> is a feature introduced in the popular Google email
service back in 2018, which helps to save time on repetitive writing by
suggesting relevant contextual phrases. In this report, I explore the
approach taken to reproduce a Proof-of-Concept implementation of the
same feature using <a class="dim" href="https://www.kaggle.com/wcukierski/enron-email-dataset">the Enron Email Dataset</a>.</p>
<h3 id="previous-work">Previous work</h3>
<p>As the first step into the task, I searched for some information about
the technical implementation. The Google Teams published a paper called
&quot;<a class="dim" href="https://dl.acm.org/doi/abs/10.1145/3292500.3330723">Gmail Smart Compose: Real-Time Assisted Writing</a>&quot;  in July 2019 covering
much of the challenges and implementation details needed to try to
experiment it on my own.</p>
<p>An additional article &quot;<a class="dim" href="https://towardsdatascience.com/gmail-style-smart-compose-using-char-n-gram-language-models-a73c09550447">Building Gmail style smart compose with a char
ngram language model</a>&quot;  from the Machine Learning community helped to
gather additional information and implementation details.</p>
<p>Then most of the code contributions came from the official Keras
documentation for sequence-to-sequence models: &quot;<a class="dim" href="https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html">A ten-minute
introduction to sequence-to-sequence learning in Keras</a>&quot;  and &quot;<a class="dim" href="https://keras.io/examples/lstm_seq2seq/">Sequence
to sequence example in Keras (character-level)</a>&quot; .</p>
<h3 id="environment-limits">Environment limits</h3>
<p>The project has been developed mainly using the Colab free plan, thus
subject to the limit of 13GB RAM. Also, because of the educational
purposes of the project, I aimed for training time within the range of
30-60mins.</p>
<h2 id="architecture">Architecture</h2>
<p>The fundamental task in Smart Compose is to predict a sequence of tokens
of variable length, conditioned on the prefix token sequence typed by a
user and additional contextual information. During training, the
objective is to maximize the log probability of producing the correct
target sequence given the input for all data samples in the training
corpus.</p>
<h3 id="data">Data</h3>
<p>The biggest public email dataset available is the Enron email dataset,
which contains approximately 500,000 emails generated by employees of
the Enron Corporation. It was obtained by the Federal Energy Regulatory
Commission during its investigation of Enron’s collapse. Despite its
relatively big size (Google trained their models on billions of emails),
the usage of this dataset has faced different challenges.</p>
<h4 id="previous-email">Previous email</h4>
<p>An important information for the prediction of the completion is the
content of the previous email in case the composed one is a response.
Unfortunately, the Enron dataset is a flatten set of emails with no
information about conversations other than the subject, such ash
<code class="purple">Re: hello</code>. The subject, however, is too fragile to use to safely
group emails as related, and it’s also often missing as value within the
samples. According to the paper, merely joining the subject and the
previous email to the model input reduces the log perplexity (the metric
used to evaluate the models) is reduced by 0.13, which is a significant
improvement.</p>
<p>Another important consequence is that the only relevant information to
use as input of the model is the sentence the user is composing.</p>
<h4 id="preprocessing">Preprocessing</h4>
<p>Preprocessing was a very important step of the project and required
careful handling. This is the biggest difference I experienced compared
to usual tutorials or exercises, where the dataset is just loaded, and
it’s already prepared for the task.</p>
<p>The emails are tokenized into words and essential punctuation marks like
<code class="purple">. ? ! , ’</code>. Other special marks like new lines are removed and multiple
white spaces are compacted as single whitespaces.</p>
<p>Quoted and forwarded messages are removed from the dataset, along with
emails longer than 100 words. The latter removal has been done for two
purposes: long emails tend to be uncommon to be written again by the
user and the increase the required memory and training time by a great
amount. Likewise, sentences longer than 20 words are not considered. The
model is aimed to learn common sentences which are usually below the
threshold of 20 words.</p>
<p>This process resulted in approximately 57 000 sentences.</p>
<h4 id="data-sequences">Data sequences</h4>
<p>In order to generate the context of a sentence, we train the
sequence-to-sequence model to predict the sentence completion from pairs
of split sentences of variable length. For instance, the sentence
<code class="purple">here is our forecast</code> is split in the following pairs within the
dataset:</p>
<pre><code>[
   (&#39;&lt;start&gt; here is &lt;end&gt;&#39;, &#39;&lt;start&gt; our forecast &lt;end&gt;&#39;)
   (&#39;&lt;start&gt; here is our &lt;end&gt;&#39;, &#39;&lt;start&gt; forecast &lt;end&gt;&#39;)
   (&#39;&lt;start&gt; way to &lt;end&gt;&#39;, &#39;&lt;start&gt; go !!! &lt;end&gt;&#39;)
   (&#39;&lt;start&gt; way to go &lt;end&gt;&#39;, &#39;&lt;start&gt; !!! &lt;end&gt;&#39;)
   (&#39;&lt;start&gt; let&#39;s shoot &lt;end&gt;&#39;, &#39;&lt;start&gt; for tuesday at . &lt;end&gt;&#39;)
   (&#39;&lt;start&gt; let&#39;s shoot for &lt;end&gt;&#39;, &#39;&lt;start&gt; tuesday at . &lt;end&gt;&#39;)
   (&#39;&lt;start&gt; let&#39;s shoot for tuesday &lt;end&gt;&#39;, &#39;&lt;start&gt; at . &lt;end&gt;&#39;)
   (&#39;&lt;start&gt; let&#39;s shoot for tuesday at &lt;end&gt;&#39;, &#39;&lt;start&gt; . &lt;end&gt;&#39;)
]
</code></pre><p>Unique tokens <code class="purple">&lt;start&gt;</code> and <code class="purple">&lt;end&gt;</code> are added to delimit the limits on
the input and output sequences. This is both similar to usual Neural
Machine Translation (NMT) where the model is given the task to predict
from the input sequence <code class="purple">&lt;start&gt; The weather is nice &lt;end&gt;</code> the output
sequence <code class="purple">&lt;start&gt; Il fault beau &lt;end&gt;</code></p>
<p>This resulted in approximately 500 000 pairs of sequences.</p>
<h4 id="tokenization">Tokenization</h4>
<p>The previous text corpora are transformed into sequences of integers
(each integer being the index of a token in a dictionary) by using Keras
<code class="purple">Tokenizer</code>. I also put a limit to the 10k most frequent words, deleting
uncommon words from sentences. This reduces the number of parameters
needed to learn in the model and thus the training time.</p>
<p>Sequences are then padded to have the same length, shuffled to avoid
pairs from the same sentence to be contiguous, and they are finally
ready to be served to the neural model.</p>
<h3 id="natural-language-model">Natural Language Model</h3>
<p>Considering the limits of the available dataset, as mentioned in the
previous section, the project used the Sequence-to-Sequence Model
(seq2seq) similar to NMT, where the source sequence is the start of the
sentence and the target sequence the completion. The original paper also
uses an attention mechanism to provide better a understanding of the
context, but it has been left as potential improvement of the project.</p>
<h4 id="training-model">Training model</h4>
<p>The following image provides an overview of the final seq2seq model used
for training. At its core, it’s an Encoder-Decoder model which uses GRU
units to encode the input context.</p>
<p>
    <figure>
      <a href="/images/gmail-smart-compose-keras/model.png" target="_blank" rel="noopener noreferrer">
        <img class="lozad" data-src="/images/gmail-smart-compose-keras/model.png" alt="The layers of the seq2seq model">
      </a>
      <figcaption class="f6 i tr mt1">The layers of the seq2seq model</figcaption>
    </figure>
  </p>
<ul>
<li><p>The first layer takes as input the start of the sentences as
sequences of integers returned by the <code class="purple">Tokenizer</code>and padded to have
the same length, 21 integers.</p>
</li>
<li><p>An embedding layer is used to improve the training. The dimension is
set as 10 by following the general advice of using
\(vocabulary\_size^{0.25}\) as embedding size as suggested in
&quot;<a class="dim" href="https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html">Introducing TensorFlow Feature Columns</a>&quot; . The main motivation of
the usage of an embedding layer is to introduce the ability to
recognize that two sequences are similar without losing the ability
to encode both sequences as distinct from the other, while sharing
the statistical strength between the two of them and their context.
For instance, the two sequences <code class="purple">Have a great</code> and <code class="purple">Have a good</code>
should have the same completion <code class="purple">&lt;start&gt; weekend &lt;end&gt;</code>.</p>
</li>
<li><p>The Encoder is comprised of a Bidirectional Gated Recurrent Units
(GRU) layer. GRU units have been used as a gating mechanism to
better encode the input sequences compared to common RNN. The latter
suffers the vanishing gradient issue, especially with the case of
the sequences in this dataset which reach a length of 20 words.
Compared instead to Long short-term memory (LSTM) units, GRU units
have been proved in practice to perform better with the task under
consideration. Furthermore, GRU units have only one state, the
Hidden State, whereas an Encoder with LSTM units requires working
with both the Hidden States and the Cell states. Finally, since the
usage of the Bidirectional model, both the forward and backward
Hidden States are concatenated to form a single Encoded Hidden
State.</p>
</li>
<li><p>During the training, the model uses <strong>teacher forcing</strong>. Specifically, it is trained to
turn the target sequences into the same sequences but offset by one
time-step in the future. After the model is trained, the <code class="purple">&lt;start&gt;</code>
token can be used to start the process and the generated word in the
output sequence is used as input on the subsequent time step.
However, during the training, we obtain values which are likely to
be different from the ground truth and they set the model off track
because every subsequently generated word will be based on a wrong
history. For this reason, during the training, the model receives
the ground truth output (y^t) as input at time <code class="purple">t + 1</code>. This
explains the usage of an additional Input Layer and Embedding,
containing the ground truth sequence.</p>
<p>
    <figure>
      <a href="/images/gmail-smart-compose-keras/autoencoder-training.png" target="_blank" rel="noopener noreferrer">
        <img class="lozad" data-src="/images/gmail-smart-compose-keras/autoencoder-training.png" alt="Teacher forcing during training">
      </a>
      <figcaption class="f6 i tr mt1">Teacher forcing during training</figcaption>
    </figure>
  </p>
</li>
<li><p>The Decoder is comprised of a GRU layer which takes as input the
Encoded Hidden State and the ground truth output from the previous
time-step. Then a Dropout layer is added to its output to avoid
overfitting, and an additional Dense layer is used to improve
inference capabilities. Finally, the last Dense layer produces the
logits for each word in the dictionary, assigning to each of them a
probability of being the correct word to predict. Since the
categories are provided as integers, the function used as loss is
<code class="purple">sparse_categorical_crossentropy</code> whereas <code class="purple">perplexity</code> is the
metric.</p>
<p>$$log\ Perplexity(x) = -\sum_x{p(x)\ log\ p(x)}$$</p>
<p><code class="purple">x</code> is the ground truth label and <code class="purple">p(x)</code> is the model. The lower
is the perplexity, and the higher is the probability of assigning
the true target tokens. Perplexity is a typical metric used to
evaluate language model and it’s the same used in the Google paper.</p>
</li>
</ul>
<p>In the following table the results of different
architectures or hyper-parameters.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Architecture</th>
<th style="text-align:center"># Parameters</th>
<th style="text-align:center">Training time</th>
<th style="text-align:center">Perplexity</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Forward-only GRU 128 outputs with a Decoder Dense Layer of 128 units</td>
<td style="text-align:center">1,614,032</td>
<td style="text-align:center">32min</td>
<td style="text-align:center">2.0357</td>
</tr>
<tr>
<td style="text-align:left">Bidirectional LSTM 128 outputs with a Decoder Dense Layer of 128 units</td>
<td style="text-align:center">1,938,640</td>
<td style="text-align:center">35min</td>
<td style="text-align:center">1.9327</td>
</tr>
<tr>
<td style="text-align:left">Bidirectional GRU 128 outputs with a Decoder Dense Layer of 128 units</td>
<td style="text-align:center">1,836,240</td>
<td style="text-align:center">34min</td>
<td style="text-align:center">1.8793</td>
</tr>
<tr>
<td style="text-align:left">Bidirectional GRU 128 outputs with a Decoder Dense Layer of 256 units</td>
<td style="text-align:center">3,149,136</td>
<td style="text-align:center">61min</td>
<td style="text-align:center">1.6835</td>
</tr>
<tr>
<td style="text-align:left">Bidirectional GRU 64 outputs with a Decoder Dense Layer of 128 units</td>
<td style="text-align:center">941,200</td>
<td style="text-align:center">24min</td>
<td style="text-align:center">2.3211</td>
</tr>
<tr>
<td style="text-align:left">Bidirectional GRU 192 outputs with a Decoder Dense Layer of 192 units</td>
<td style="text-align:center">2,895,120</td>
<td style="text-align:center">57min</td>
<td style="text-align:center">1.7118</td>
</tr>
<tr>
<td style="text-align:left">Bidirectional GRU 192 outputs with a Decoder Dense Layer of 128 units</td>
<td style="text-align:center">2,230,480</td>
<td style="text-align:center">41min</td>
<td style="text-align:center">1.8352</td>
</tr>
</tbody>
</table>
<p>Despite the best model is 128 GRU outputs with 256 units in the hidden Dense layer, the model has much more parameters and therefore incurs also in slower inference time later. Since inference latency is an important metric for the task under consideration, I preferred to keep the model with 192 GRU outputs and 128 units in the hidden layer. It is the second best-scoring model but with ~2.2mln parameters compared to ~3.2mln parameters of the best-absolute model.</p>
<h4 id="inference-model">Inference Model</h4>
<p>During the inference, the model uses separately the Encoder to encode
the input sequence whereas the Decoder will not be fed with the true
output and it’s approximated with the model’s output at the previous
time-step.</p>
<p>
    <figure>
      <a href="/images/gmail-smart-compose-keras/autoencoder-inference.png" target="_blank" rel="noopener noreferrer">
        <img class="lozad" data-src="/images/gmail-smart-compose-keras/autoencoder-inference.png" alt="Prediction re-injected during
inference">
      </a>
      <figcaption class="f6 i tr mt1">Prediction re-injected during
inference</figcaption>
    </figure>
  </p>
<p>The Encoder uses the same layers of the training
Encoder-Decoder.</p>
<p>
    <figure>
      <a href="/images/gmail-smart-compose-keras/encoder.png" target="_blank" rel="noopener noreferrer">
        <img class="lozad" data-src="/images/gmail-smart-compose-keras/encoder.png" alt="The Inference Encoder">
      </a>
      <figcaption class="f6 i tr mt1">The Inference Encoder</figcaption>
    </figure>
  </p>
<p>Likewise, the Inference Decoder uses the same
layers as before, with the only difference that it uses the word
predicted at the previous step as input along with the Encoded Hidden
State.</p>
<p>
    <figure>
      <a href="/images/gmail-smart-compose-keras/inf-model.png" target="_blank" rel="noopener noreferrer">
        <img class="lozad" data-src="/images/gmail-smart-compose-keras/inf-model.png" alt="Layers in the Inference Decoder model">
      </a>
      <figcaption class="f6 i tr mt1">Layers in the Inference Decoder model</figcaption>
    </figure>
  </p>
<p>The inference Decoder predicts the sentence completion by doing the
following steps:</p>
<ol>
<li><p>It tokenizes and embeds the input sequence using the same
preprocessing of the training inputs</p>
</li>
<li><p>The Encoder returns the Encoded Hidden State</p>
</li>
<li><p>The target sequence starts with only the <code class="purple">&lt;start&gt;</code> token and is
conditioned to generate an output work token based on the context
provided by the Encoded Hidden State. The</p>
</li>
<li><p>Step 3 is repeated until the token <code class="purple">&lt;end&gt;</code> is generated. The final
sequence is converted back from integer tokens to words using the
reverse dictionary of the <code class="purple">Tokenizer</code>.</p>
</li>
</ol>
<h2 id="evaluation">Evaluation</h2>
<p>Below there are some results provided by the inference.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Input</th>
<th style="text-align:left">Output</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">here is</td>
<td style="text-align:left">the latest version of the usec transaction &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">have a</td>
<td style="text-align:left">good weekend &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">please review</td>
<td style="text-align:left">and let&#39;s discuss &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">please call me</td>
<td style="text-align:left">at &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">thanks for</td>
<td style="text-align:left">the help &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">let me</td>
<td style="text-align:left">know if you have any questions . &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">Let me know</td>
<td style="text-align:left">if you have any questions . &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">Let me know if you</td>
<td style="text-align:left">have any questions &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">this sounds</td>
<td style="text-align:left">good &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">is this call going to</td>
<td style="text-align:left">get a look at this ? thanks &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">can you get</td>
<td style="text-align:left">a look at this problem ? thanks &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">is it okay</td>
<td style="text-align:left">? &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">it should</td>
<td style="text-align:left">be the absolute latest &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">call if there&#39;s</td>
<td style="text-align:left">okay with you &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">gave her a</td>
<td style="text-align:left">call &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">i will let</td>
<td style="text-align:left">you know if you have any questions &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">i will be</td>
<td style="text-align:left">there &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">may i get a copy of all the</td>
<td style="text-align:left">invoices ? thanks &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">how is our trade</td>
<td style="text-align:left">? &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">this looks like a</td>
<td style="text-align:left">good idea &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">i am fine with the changes</td>
<td style="text-align:left">. &lt;end&gt;</td>
</tr>
<tr>
<td style="text-align:left">please be sure this</td>
<td style="text-align:left">is the morale booster &lt;end&gt;</td>
</tr>
</tbody>
</table>
<p>The predicted outputs are actually quite good. The inference model is especially good with short common sentences like <em>&quot;Let me know if you have any questions&quot;</em> or <em>&quot;I will let you know&quot;</em>. Some predictions also show that the predictions are personalized based on the Enron dataset, for instance in the case of <em>&quot;here is the latest version of the usec transaction&quot;</em>.</p>
<p>Unfortunately, some other cases such as <em>&quot;call if there&#39;s okay with you&quot;</em> or <em>&quot;please be sure this is the morale booster&quot;</em> seem to be a bit off. If we had a bigger dataset and more training time these completions should have been discarded as very unlikely to be correct.</p>
<h2 id="inference-in-the-browser">Inference in the browser</h2>
<p>Because the model must be used to predict email autocompletion, the next
step is to save the model and make the inference on the fly while the
user types. This can be done on the server or on directly in the
browser. Because of the low-latency requirements and the cost of renting
an ever-running server, the decision has been to try using the model
within the browser.</p>
<p>For this goal, both the <code class="purple">Tokenizer</code> dictionary and the Keras model must
be saved and loaded later in the browser. The word-to-integer dictionary
is just saved as JSON, whereas I found that <code class="purple">H5</code> is the best working
format for the Keras model. Attempts to use the Tensorflow <a class="dim" href="https://www.tensorflow.org/guide/saved_model">SavedModel</a> 
resulted in errors while converting the model to the web using
<a class="dim" href="https://www.tensorflow.org/js/guide/conversion">tensorflowjs-converter</a>.</p>
<p>The model is then loaded in the browser along with the pre-trained
weights using <a class="dim" href="https://www.tensorflow.org/js">Tensorflow.js</a> , a JavaScript implementation of the
framework. In particular, because JavaScript executes in a single main
thread shared with UI rendering, in order to avoid freezing the page
while loading the model or during the inference calculations, all the
Keras processing is done in a separate thread via <a class="dim" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers">Web Worker</a>.</p>
<p>The main thread communicates with the Web Worker via messages, and the
latter executes the tokenization of the input sequence and the
subsequent model inference. Then the result is returned to the browser
main thread via message again.</p>
<p>
    <figure>
      <a href="/images/gmail-smart-compose-keras/keras-web-worker.png" target="_blank" rel="noopener noreferrer">
        <img class="lozad" data-src="/images/gmail-smart-compose-keras/keras-web-worker.png" alt="A representation of Model inference in the
browser">
      </a>
      <figcaption class="f6 i tr mt1">A representation of Model inference in the
browser</figcaption>
    </figure>
  </p>
<p>The final source code are available on the repository at
<a class="dim" href="https://github.com/jiayihu/gmail-smart-compose">github.com/jiayihu/gmail-smart-compose</a>.
For easier evaluation, there is also a <a class="dim" href="https://colab.research.google.com/drive/1wjr-Ntnd4zYMneyGUz1beEmyw0fwgnEG?usp=sharing">notebook on
Colab</a>.</p>
<h2 id="conclusions">Conclusions</h2>
<p>The project has been the first real-world usage of NLP notions and Deep
Learning techniques. The most important lessons have been:</p>
<ol>
<li><p>Before even thinking about the learning model, there is a lot of
work that needs to be done during the preprocessing phase. The
available dataset to be used as input for the model assumes an
important role on the subsequent training and goodness of the
results. I would dare to say that data quality is as important as
the training model. Unfortunately the Enron dataset is the only
meaningful dataset but is lacking important information like linking
responses.</p>
</li>
<li><p>Training real-world models requires a lot of RAM and computing
power. The project has been trained using Colab free plan which
limits the available RAM to 13GB and there are also limitations on
the amount of GPU usage. Although this prohibited the training of
more complex models or for a long time, at first it forced me to
think better about the data structures I was using and the amount of
input used to generate the dataset. I started to be more careful
about what to include in the dataset, which resulted in both less
RAM usage and more accurate inference predictions. At the same time,
there are obviously strongs disadvantages in limited RAM and
training time. According to the paper, Google ran their models on
billions of emails and for at least 3 days using high-end TPUs. But
for educational purposes, 13GB should be enough to learn something
meaningful.</p>
</li>
</ol>
</div>
        </div>
      </section>
    </article>

    <div class="comments measure-wide center ph2 ph0-l">
  <script>var ISSUE_ID = '40';</script>

  <h3>Comments</h3>

  
    <div class="br2 ba b--lightest-blue bg-washed-blue f6 mb5">
      <div class="flex items-center">
        <div class="fg1 pa3">
          <div>
            <p class="black-70 measure lh-copy mv0">
              This blog is using GitHub Issues as comments. You can post by replying to issue
              <a href="https://github.com/jiayihu/blog/issues/40#new_comment_field" class="link black f5 underline-hover" target="_blank" rel="noopener noreferrer">
                #40
              </a>
            </p>
          </div>
        </div>
        <div class="w5 pa3">
          <a href="https://github.com/jiayihu/blog/issues/40#new_comment_field" class="link no-underline f6 tc db w-100 pv3 bg-animate bg-dark-green hover-bg-dark-blue white br2" target="_blank" rel="noopener noreferrer">
            Post a comment
          </a>
        </div>
      </div>
    </div>
  

  <div class="comments-content"></div>

  <!-- HTML put to avoid uncss removing the CSS classes needed by async comments -->
  <ul class="list pl0 dn">
    <li class="comment flex mt3">
      <div class="comment__author mr2 tc">
        <a href="https://github.com/jiayihu" class="dib h2--half w2--half">
          <img src="https://avatars1.githubusercontent.com/u/10067273?v=4" alt="jiayihu" class="br2 h2--half w2--half dib">
        </a>
      </div>
      <div class="fg1 br2 ba b--moon-gray f6 measure-wide">
        <div class="comment__header bb b--moon-gray bg-black-05 flex items-center silver ph3 pv2">
          <span>
            <a href="https://github.com/jiayihu" class="link underline-hover near-black">
              jiayihu
            </a>
            commented
            <a href="https://github.com/jiayihu/blog/issues/2#issuecomment-394303150" class="link underline-hover silver">
              2 weeks ago
            </a>
          </span>
          <span class="ba b--moon-gray br2 mla f7 fw7 ph2 pv1">Author</span>
        </div>
        <div class="comment__body pa3"></div>
    </div></li>
  </ul>
</div>
 <footer class="pv4 ph3 ph5-ns tc mt4">
  <a class="link dim gray dib h2 w2 br-100 mr3" href="https://twitter.com/jiayi_ghu" title="">
    <svg data-icon="twitter" viewBox="0 0 32 32" style="fill: currentcolor;">
      <title>twitter icon</title>
      <path
        d="M2 4 C6 8 10 12 15 11 A6 6 0 0 1 22 4 A6 6 0 0 1 26 6 A8 8 0 0 0 31 4 A8 8 0 0 1 28 8 A8 8 0 0 0 32 7 A8 8 0 0 1 28 11 A18 18 0 0 1 10 30 A18 18 0 0 1 0 27 A12 12 0 0 0 8 24 A8 8 0 0 1 3 20 A8 8 0 0 0 6 19.5 A8 8 0 0 1 0 12 A8 8 0 0 0 3 13 A8 8 0 0 1 2 4"
      ></path>
    </svg>
  </a>
  <a class="link dim gray dib br-100 h2 w2 mr3" href="https://github.com/jiayihu" title="">
    <svg data-icon="github" viewBox="0 0 32 32" style="fill: currentcolor;">
      <title>github icon</title>
      <path
        d="M0 18 C0 12 3 10 3 9 C2.5 7 2.5 4 3 3 C6 3 9 5 10 6 C12 5 14 5 16 5 C18 5 20 5 22 6 C23 5 26 3 29 3 C29.5 4 29.5 7 29 9 C29 10 32 12 32 18 C32 25 30 30 16 30 C2 30 0 25 0 18 M3 20 C3 24 4 28 16 28 C28 28 29 24 29 20 C29 16 28 14 16 14 C4 14 3 16 3 20 M8 21 A1.5 2.5 0 0 0 13 21 A1.5 2.5 0 0 0 8 21 M24 21 A1.5 2.5 0 0 0 19 21 A1.5 2.5 0 0 0 24 21 z"
      ></path>
    </svg>
  </a>
  <a class="link dim gray dib br-100 h2 w2 mr3" href="https://www.linkedin.com/in/jiayi-hu/" title="LinkedIn">
    <svg
      fill="currentColor"
      xmlns="http://www.w3.org/2000/svg"
      viewBox="0 0 16 16"
      fill-rule="evenodd"
      clip-rule="evenodd"
      stroke-linejoin="round"
      stroke-miterlimit="1.414"
    >
      <title>LinkedIn icon</title>
      <path
        d="M13.632 13.635h-2.37V9.922c0-.886-.018-2.025-1.234-2.025-1.235 0-1.424.964-1.424 1.96v3.778h-2.37V6H8.51V7.04h.03c.318-.6 1.092-1.233 2.247-1.233 2.4 0 2.845 1.58 2.845 3.637v4.188zM3.558 4.955c-.762 0-1.376-.617-1.376-1.377 0-.758.614-1.375 1.376-1.375.76 0 1.376.617 1.376 1.375 0 .76-.617 1.377-1.376 1.377zm1.188 8.68H2.37V6h2.376v7.635zM14.816 0H1.18C.528 0 0 .516 0 1.153v13.694C0 15.484.528 16 1.18 16h13.635c.652 0 1.185-.516 1.185-1.153V1.153C16 .516 15.467 0 14.815 0z"
        fill-rule="nonzero"
      />
    </svg>
  </a>
  <small class="mt4 f6 db tc">© 2020. All Rights Reserved</small>
</footer>

<script src="https://polyfill.io/v3/polyfill.min.js?features=default%2Cfetch"></script>
<script src="/js/main.js"></script>
<script src="/js/prism.js"></script>

<script>
  (function (i, s, o, g, r, a, m) {
    i["GoogleAnalyticsObject"] = r;
    (i[r] =
      i[r] ||
      function () {
        (i[r].q = i[r].q || []).push(arguments);
      }),
      (i[r].l = 1 * new Date());
    (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m);
  })(
    window,
    document,
    "script",
    "https://www.google-analytics.com/analytics.js",
    "ga"
  );

  ga("create", "UA-103053006-1", "auto");
  ga("send", "pageview");
</script>


    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </body>
</html>
